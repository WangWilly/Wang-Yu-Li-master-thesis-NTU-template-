\chapter{緒論}


\section{動機}
在歌聲分離 (singing voice separation, SVS) 中，隨著時代演進，硬體與軟體越來越適合深度學習方法，與傳統方法相比，大幅提升了此領域的表現，各大串流媒體公司競相發展此領域的研究，如： Line 、 Spotify~\cite{jansson2017singing} 、 Deezer~\cite{hennequin2020spleeter} 與 FaceBook~\cite{defossez2019music} 等等。將迅速且準確的深度神經模型植入到晶片中，其模型必須達到兩大重點：儲存空間小、預測延遲低 (low latency) ，目標是在有限的分離效果與延遲妥協之下，可以應用在端點裝置如麥克風或是手機中。
% [應用面]
人聲分離可應用至多數音樂產業之中，在歌聲分離領域發展完善的情況下，除了可以對音樂產業有更多協助，亦可衍生出更多音樂資訊的研究，像是：vocal melody extraction（歌聲旋律抽取）、singer identification（歌手辨認）與 vocal and lyrics alignment（歌聲與歌詞自動對位）。


\section{研究方向與主要貢獻}
% 假設: 聲音會有重複情形 (demucs 中提到)
在前述的需求情景下，本論文主要根據對音樂在時間軸上會有重複性的假設，使用對應的注意力架構 (attention mechanism)~\cite{vaswani2017attention,oktay2018attention,shaw2018self,liu2020voice} 既有 U-Net 模型~\cite{ronneberger2015u} 的強化，希望模型能因此效果更好，本論文最後針對不同的注意力架構進行比較，加上模型壓縮的效能落差。模型壓縮本文使用了兩個方法：模型剪枝與模型量化，前者使用了「深度可分卷積」~\cite{chollet2017xception,howard2017mobilenets} 與「inverted residual」~\cite{sandler2018mobilenetv2} 兩個針對卷積參數降低的方法，後者使用 PyTorch 提供的 QNNPACK~\cite{dukhan2018qnnpack,wu2019machine} 將模型從浮點參數量化至整數參數，節省儲存資源並降低運算的時間。

\section{章節概要}
以下為各章節的概述：
% \begin{itemize}[wide=1cm, leftmargin=*]
\begin{itemize}
	\item 第一章簡單介紹本次研究的主題以及相關應用，並概述研究目的和使用的研究方法。
	\item 第二章介紹過去的相關研究，依照傳統作法與機器學習作法分別說明，並簡單介紹使用到的相關技術。
	\item 第三章詳細介紹本次研究中使用的資料集，依照訓練資料、測試資料分別介紹，並提及用何種規格進行資料讀取。
	\item 第四章定義本次實驗研究的問題，並介紹研究使用的深度學習模型、實驗設計和其他相關實驗設定，以及評量指標。
	\item 在第五章以視覺化方式展示各項實驗結果，並進行錯誤分析。
	\item 第六章對各項實驗結果總結我們研究的發現，並提出本次研究的未來展望。
\end{itemize}